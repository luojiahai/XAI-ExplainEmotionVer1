{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from menpodetect import load_opencv_frontal_face_detector\n",
    "opencv_detector = load_opencv_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_images, path_to_labels):\n",
    "    images = []\n",
    "    labels = []\n",
    "    (image_paths, raw_labels) = get_files(path_to_images, path_to_labels)\n",
    "\n",
    "    for i in range(len(image_paths)):\n",
    "        try:\n",
    "            image = load_image(image_paths[i])\n",
    "            _ = load_vector(image)\n",
    "            images.append(image)\n",
    "            labels.append(raw_labels[i])\n",
    "        except ValueError:\n",
    "#             print(\"Not squared\")\n",
    "            continue\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(images_path, labels_path):\n",
    "    images_dirs = get_dirs(images_path)\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for dir in images_dirs:\n",
    "        try:\n",
    "            dir_path = os.path.join(dir.split(os.sep)[-2], dir.split(os.sep)[-1])\n",
    "            label = os.listdir(os.path.join(labels_path, dir_path))[0]\n",
    "            label_dir = os.path.join(os.path.join(labels_path, dir_path), label)\n",
    "            label_f = open(label_dir, \"r\")\n",
    "            line = label_f.readline()\n",
    "            labels.append(int(float(line.rstrip())))\n",
    "\n",
    "            image = sorted(os.listdir(dir))[-1]\n",
    "            image_path = os.path.join(dir, image)\n",
    "            images.append(image_path)\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "        except IndexError:\n",
    "            continue\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirs(path):\n",
    "    sub_dirs = [os.path.join(path, o) for o in os.listdir(path) \n",
    "                    if os.path.isdir(os.path.join(path,o))]\n",
    "    if (len(sub_dirs) == 0):\n",
    "        return [path]\n",
    "    else:\n",
    "        l = []\n",
    "        for sub_dir in sub_dirs:\n",
    "            l.extend(get_dirs(sub_dir))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "\n",
    "def load_image(path_to_image):\n",
    "    image = misc.imread(path_to_image, mode='L')\n",
    "    image = misc.imresize(image, [400, 400])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import menpo\n",
    "from menpo.feature import vector_128_dsift\n",
    "\n",
    "def load_vector(image):\n",
    "    image = menpo.image.Image(image)\n",
    "    if image.n_channels != 1:\n",
    "        image = image.as_greyscale()\n",
    "    opencv_detector(image)\n",
    "    try:\n",
    "        image = image.crop_to_landmarks_proportion(0.2).rescale_landmarks_to_diagonal_range(400)\n",
    "    except:\n",
    "#         print(\"No face detected\")\n",
    "        None\n",
    "    vector = vector_128_dsift(image).reshape(128)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\menpo\\image\\base.py:2685: MenpoDeprecationWarning: This method is no longer supported and will be removed in a future version of Menpo. Use .pixels_with_channels_at_back() instead.\n",
      "  MenpoDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "(images, labels) = load_data(path_to_images=os.path.normpath(\"data\\ck+\\extended-cohn-kanade-images\\cohn-kanade-images\"),\n",
    "                             path_to_labels=os.path.normpath(\"data\\ck+\\Emotion_labels\\Emotion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# Define PipeStep class\n",
    "class PipeStep(object):\n",
    "        \"\"\"\n",
    "        Wrapper for turning functions into pipeline transforms (no-fitting)\n",
    "        \"\"\"\n",
    "        def __init__(self, step_func):\n",
    "            self._step_func=step_func\n",
    "        def fit(self,*args):\n",
    "            return self\n",
    "        def transform(self,X):\n",
    "            return self._step_func(X)\n",
    "\n",
    "# Define steps\n",
    "makegray_step = PipeStep(lambda img_list: [rgb2gray(img) for img in img_list])\n",
    "vectorize_step = PipeStep(lambda img_list: [load_vector(img) for img in img_list])\n",
    "\n",
    "# Construct Pipeline\n",
    "classifier = Pipeline([('Makegray', makegray_step),\n",
    "                       ('Vectorize', vectorize_step),\n",
    "                       ('SVM', svm.SVC(kernel='linear', probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\menpo\\image\\base.py:2685: MenpoDeprecationWarning: This method is no longer supported and will be removed in a future version of Menpo. Use .pixels_with_channels_at_back() instead.\n",
      "  MenpoDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('Makegray', <__main__.PipeStep object at 0x000002174B4806D8>), ('Vectorize', <__main__.PipeStep object at 0x000002174B480780>), ('SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\menpo\\image\\base.py:2685: MenpoDeprecationWarning: This method is no longer supported and will be removed in a future version of Menpo. Use .pixels_with_channels_at_back() instead.\n",
      "  MenpoDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.17      0.29      0.21         7\n",
      "          2       0.67      0.25      0.36         8\n",
      "          3       0.70      0.78      0.74         9\n",
      "          4       0.33      0.25      0.29         4\n",
      "          5       0.88      0.82      0.85        17\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.85      0.69      0.76        16\n",
      "\n",
      "avg / total       0.68      0.59      0.61        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Test\n",
    "pred_test = classifier.predict(X_test)\n",
    "pred_prop = classifier.predict_proba(X_test)\n",
    "print(classification_report(y_true=y_test, y_pred=pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02656171  0.03228368  0.01333562  0.05082742  0.00367976  0.21051479\n",
      "   0.66279702]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\menpo\\image\\base.py:2685: MenpoDeprecationWarning: This method is no longer supported and will be removed in a future version of Menpo. Use .pixels_with_channels_at_back() instead.\n",
      "  MenpoDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "image = load_image('data/test3-7.png')\n",
    "pred_prop_1 = classifier.predict_proba([image])\n",
    "print(pred_prop_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\menpo\\image\\base.py:2652: MenpoDeprecationWarning: This method is no longer supported and will be removed in a future version of Menpo. Use .pixels_with_channels_at_back instead.\n",
      "  MenpoDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "# Explain\n",
    "explainer = lime_image.LimeImageExplainer(verbose = False)\n",
    "segmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)\n",
    "explanation = explainer.explain_instance(image, \n",
    "                                         classifier_fn = classifier.predict_proba, \n",
    "                                         top_labels=3, hide_color=0, num_samples=1000, segmentation_fn=segmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.colors' has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     37\u001b[0m             display(\n\u001b[0;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             )\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;31m# determine if a background is needed for legibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;31m# the background is transparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[1;32mC:\\Users\\hoipc\\AppData\\Local\\conda\\conda\\envs\\conda_env\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36m_is_transparent\u001b[1;34m(color)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mrgba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib.colors' has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "# now show them for each class\n",
    "fig, m_axs = plt.subplots(2,3, figsize = (12,4))\n",
    "for i, (c_ax, gt_ax) in zip(explanation.top_labels, m_axs.T):\n",
    "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=5, hide_rest=False, min_weight=0.01)\n",
    "    c_ax.imshow(label2rgb(mask,temp, bg_label = 0), interpolation = 'nearest')\n",
    "    c_ax.set_title('Positive for {}\\nScore:{:2.2f}%'.format(i+1, 100*pred_prop_1[0, i]))\n",
    "    c_ax.axis('off')\n",
    "    face_id = np.random.choice(np.where(y_train==i+1)[0])\n",
    "    gt_ax.imshow(X_train[face_id])\n",
    "    gt_ax.set_title('Example of {}'.format(i+1))\n",
    "    gt_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
